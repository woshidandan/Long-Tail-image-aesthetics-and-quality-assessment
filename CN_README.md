# Long-Tail-image-aesthetics-and-quality-assessment
ICML2024: é¦–ç¯‡é’ˆå¯¹IAAä¸­çš„é•¿å°¾é—®é¢˜æå‡ºè§£å†³æ–¹æ¡ˆçš„å·¥ä½œ


[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Framework](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?&logo=PyTorch&logoColor=white)](https://pytorch.org/)


<div align="center">
<h1>
<b>
ELTA: An Enhancer against Long-Tail for Aesthetics-oriented Models
</b>
</h1>
<h4>
<b>
Limin Liu*, Shuai He*, Anlong Ming*, Rui Xie, Huadong Ma
    
Beijing University of Posts and Telecommunications, *Equal contribution
</b>
</h4>
</div>

-----------------------------------------



## Introduction
ç°å®ä¸–ç•Œä¸­çš„æ•°æ®é›†å¾€å¾€å‘ˆç°é•¿å°¾åˆ†å¸ƒï¼Œå½±å“äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œå…¬å¹³æ€§ã€‚è¿™ä¸ªé—®é¢˜åœ¨å›¾åƒç¾å­¦è¯„ä¼°ï¼ˆIAAï¼‰ä»»åŠ¡ä¸­å°¤ä¸ºçªå‡ºï¼Œç”±äºç‰¹å¾å’Œæ ‡ç­¾ä¹‹é—´å­˜åœ¨ä¸¥é‡çš„åˆ†å¸ƒä¸åŒ¹é…ï¼Œä»¥åŠç¾å­¦å¯¹å›¾åƒå˜åŒ–çš„é«˜åº¦æ•æ„Ÿæ€§ï¼Œè¿™ç§ä¸å¹³è¡¡å¾ˆéš¾å¾—åˆ°ç¼“è§£ã€‚
ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é¢å‘ç¾å­¦æ¨¡å‹çš„é•¿å°¾å¢å¼ºå™¨ï¼ˆELTAï¼‰ã€‚ELTA é¦–å…ˆåˆ©ç”¨ä¸“é—¨è®¾è®¡çš„MixupæŠ€æœ¯æ¥å¢å¼ºé«˜å±‚ç©ºé—´ä¸­çš„Minorityç‰¹å¾è¡¨ç¤ºï¼ŒåŒæ—¶ä¿ç•™å›¾åƒå›ºæœ‰çš„ç¾å­¦å“è´¨ã€‚ç„¶åé€šè¿‡ç›¸ä¼¼åº¦ä¸€è‡´æ€§æ–¹æ³•å¯¹é½ç‰¹å¾å’Œæ ‡ç­¾ï¼Œæœ‰æ•ˆç¼“è§£äº†åˆ†å¸ƒä¸åŒ¹é…é—®é¢˜ã€‚æœ€åï¼ŒELTA é‡‡ç”¨äº†ä¸€ä¸ªè‡ªé€‚åº”çš„é”åŒ–ç­–ç•¥æ”¹å–„æ¨¡å‹çš„è¾“å‡ºlogitsåˆ†å¸ƒï¼Œä»è€Œæé«˜ä¼ªæ ‡ç­¾çš„è´¨é‡ã€‚

<img src="pipeline_final.png">

## ç¯å¢ƒ
* einops==0.4.1
* matplotlib==3.3.4
* nni==2.6.1
* numpy==1.19.5
* pandas==1.1.5
* Pillow==10.2.0
* scikit_learn==1.4.0
* scipy==1.5.4
* timm==0.6.12
* torch==1.10.1
* torchvision==0.11.2
* tqdm==4.64.1









## æ¨¡å‹è®­ç»ƒ
```
python main.py --csv_path           [dataset annotation file path]
               --dataset_path       [dataset image path]
               --mixup              # optional, enable TFA module
               --simloss_weight 1   # optional, enable FLSA module and specify weight
               ...                  # other arguments
```

æƒé‡æ–‡ä»¶: https://drive.google.com/file/d/1pA7kOCPHEUR5oNnocBZHH41Erud9Y30S/view?usp=drive_link

## æ¨¡å‹æ¨ç†
```
python main.py -e                   [dataset annotation file path]
               --test_dataset_path  [dataset image path]
               --resume             [checkpoint path]   # required!
               ...                  # other arguments
```

## åœ¨ç¬¬ä¸€è½®è®­ç»ƒä¹‹åå¯ç”¨è‡ªè®­ç»ƒ
```
python main.py --st                 # enable self-training
               ...                  # other arguments
```

## å»ºè®®: ä½¿ç”¨ NNI è‡ªåŠ¨è°ƒå‚
```
# è¯·å…ˆä¿®æ”¹main_nni.pyæ–‡ä»¶ä¸­å‘½ä»¤ 'trial_command' å’Œæœç´¢ç©ºé—´ 'search_space'
python main_nni.py
```

## Related Work from Our Group
<table>
  <thead align="center">
    <tr>
      <td><b>ğŸ Projects</b></td>
      <td><b>ğŸ“š Publication</b></td>
      <td><b>ğŸŒˆ Content</b></td>
      <td><b>â­ Stars</b></td>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://github.com/woshidandan/Attacker-against-image-aesthetics-assessment-model"><b>Attacker Against IAA Modelã€ç¾å­¦æ¨¡å‹çš„æ”»å‡»å’Œå®‰å…¨è¯„ä¼°æ¡†æ¶ã€‘</b></a></td>
      <td><b>TIP 2025</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Attacker-against-image-aesthetics-assessment-model?style=flat-square&labelColor=343b41"/></td>
    </tr
    <tr>
      <td><a href="https://github.com/woshidandan/Rethinking-Personalized-Aesthetics-Assessment"><b>Personalized Aesthetics Assessmentã€ä¸ªæ€§åŒ–ç¾å­¦è¯„ä¼°æ–°èŒƒå¼ã€‘</b></a></td>
      <td><b>CVPR 2025</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Rethinking-Personalized-Aesthetics-Assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment"><b>Pixel-level image exposure assessmentã€é¦–ä¸ªåƒç´ çº§æ›å…‰è¯„ä¼°ã€‘</b></a></td>
      <td><b>NIPS 2024</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Long-Tail-image-aesthetics-and-quality-assessment"><b>Long-tail solution for image aesthetics assessmentã€ç¾å­¦è¯„ä¼°æ•°æ®ä¸å¹³è¡¡è§£å†³æ–¹æ¡ˆã€‘</b></a></td>
      <td><b>ICML 2024</b></td>
      <td><b>Code</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Long-Tail-image-aesthetics-and-quality-assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Prompt-DeT"><b>CLIP-based image aesthetics assessmentã€åŸºäºCLIPå¤šå› ç´ è‰²å½©ç¾å­¦è¯„ä¼°ã€‘</b></a></td>
      <td><b>Information Fusion 2024</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Prompt-DeT?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/SR-IAA-image-aesthetics-and-quality-assessment"><b>Compare-based image aesthetics assessmentã€åŸºäºå¯¹æ¯”å­¦ä¹ çš„å¤šå› ç´ ç¾å­¦è¯„ä¼°ã€‘</b></a></td>
      <td><b>ACMMM 2024</b></td>
      <td><b>Code</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/SR-IAA-image-aesthetics-and-quality-assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Image-Color-Aesthetics-and-Quality-Assessment"><b>Image color aesthetics assessmentã€é¦–ä¸ªè‰²å½©ç¾å­¦è¯„ä¼°ã€‘</b></a></td>
      <td><b>ICCV 2023</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Image-Color-Aesthetics-and-Quality-Assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Image-Aesthetics-and-Quality-Assessment"><b>Image aesthetics assessmentã€é€šç”¨ç¾å­¦è¯„ä¼°ã€‘</b></a></td>
      <td><b>ACMMM 2023</b></td>
      <td><b>Code</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Image-Aesthetics-and-Quality-Assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/TANet-image-aesthetics-and-quality-assessment"><b>Theme-oriented image aesthetics assessmentã€é¦–ä¸ªå¤šä¸»é¢˜ç¾å­¦è¯„ä¼°ã€‘</b></a></td>
      <td><b>IJCAI 2022</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/TANet-image-aesthetics-and-quality-assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/AK4Prompts"><b>Select prompt based on image aesthetics assessmentã€åŸºäºç¾å­¦è¯„ä¼°çš„æç¤ºè¯ç­›é€‰ã€‘</b></a></td>
      <td><b>IJCAI 2024</b></td>
      <td><b>Code</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/AK4Prompts?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/mRobotit/M2Beats"><b>Motion rhythm synchronization with beatsã€åŠ¨ä½œä¸éŸµå¾‹å¯¹é½ã€‘</b></a></td>
      <td><b>IJCAI 2024</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/mRobotit/M2Beats?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC"><b>Champion Solution for AIGC Image Quality Assessmentã€NTIRE AIGCå›¾åƒè´¨é‡è¯„ä¼°èµ›é“å† å†›ã€‘</b></a></td>
      <td><b>CVPRW NTIRE 2024</b></td>
      <td><b>Code</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC?style=flat-square&labelColor=343b41"/></td>
    </tr>
  </tbody>
</table>
